{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "#使用sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "以cifar10数据集为例，将CNN和LSTM结合起来进行训练\n",
    "使用哪种卷积神经网络结构？VGGnet、inception net、Resnet\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#先构建VGGnet\n",
    "\n",
    "\n",
    "#构建浅层VGG卷积神经网络\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name = \"MaxPooling_1\"))\n",
    "'''\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))    #此时输出的是64个feature_map,每个feature_map的大小为32*32\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   #输出32*32的图像特征\n",
    "'''\n",
    "#问题：将CNN池化层处理过的图像直接输入到LSTM网络中会出现报错：\n",
    "#   ‘’Input 0 is incompatible with layer lstm_2: expected ndim=3, found ndim=4‘’\n",
    "#   解决办法：可以先读取池化层的输出图像，观察其输出维度，然后用tf.reshape进行更改\n",
    "\n",
    "#将池化层处理后的图像输出表示出来\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建LSTM网络\n",
    "\n",
    "'''\n",
    "nb_lstm_outputs = 30  #神经元个数\n",
    "nb_time_steps = 32  #时间序列长度\n",
    "nb_input_vector = 32 #输入序列\n",
    "\n",
    "\n",
    "model.add(LSTM(units=nb_lstm_outputs, input_shape=(nb_time_steps, nb_input_vector),return_sequences=True))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "#对上述构造的模型进行编译，loss表示损失函数，\n",
    "model.compile(loss='categorical_crossentropy',                                 # matt，多分类，不是binary_crossentropy\n",
    "              optimizer='rmsprop',#优化器选项，预定义一个优化器。该参数可指定为已预定义的优化器名\n",
    "              metrics=['accuracy'])#性能评估选项，如accuracy是准确率这个评估参数。\n",
    "                                   提供了一系列用于模型性能评估的函数,这些函数在模型编译时由metrics关键字设置。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在添加完LSTM网络之后，这段编译过程可以换成LSTM部分的编译过程\n",
    "\n",
    "\n",
    "#'''\n",
    "\n",
    "#Flatten是numpy下的一个函数，即返回一个折叠成一维的数组。但是该函数只能适用于numpy对象，即array或者mat，普通的list列表是不行的。\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))#全连接层，神经元个数为64个\n",
    "model.add(Activation('relu'))#激活函数\n",
    "model.add(Dropout(0.5))#Dropout是一种正则化的方法，一般放于激活函数之后\n",
    "#keras.backend.dropout(x, level, noise_shape=None, seed=None)，其中x指的是输入参数，level则是keep-prob，\n",
    "#也就是这个单元有多少概率会被设置为0。\n",
    "model.add(Dense(5))   # 全连接层，神经元个数为5个，即最后的输出为5个分类,几个分类就要有几个dense\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#对上述构造的模型进行编译，loss表示损失函数，\n",
    "model.compile(loss='categorical_crossentropy',                                 # matt，多分类，不是binary_crossentropy\n",
    "              optimizer='rmsprop',#优化器选项，预定义一个优化器。该参数可指定为已预定义的优化器名\n",
    "              metrics=['accuracy'])#性能评估选项，如accuracy是准确率这个评估参数。\n",
    "                                   #提供了一系列用于模型性能评估的函数,这些函数在模型编译时由metrics关键字设置。\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对训练集中的数据进行图像增广\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,   #值将在执行其他处理前乘到整个图像上，我们的图像在RGB通道都是0~255的整数，\n",
    "                          #这样的操作可能使图像的值过高或过低，所以我们将这个值定为0~1之间的数。\n",
    "        shear_range=0.2,  #浮点数，剪切强度（逆时针方向的剪切变换角度）。是用来进行剪切变换的程度\n",
    "        zoom_range=0.2,   #若为浮点数，则相当于[lower,upper] = [1 - zoom_range, 1+zoom_range]。用来进行随机的放大。\n",
    "        horizontal_flip=True)  #布尔值，进行随机水平翻转。随机的对图片进行水平翻转，这个参数适用于水平翻转不影响图片语义的时候。\n",
    "\n",
    "#对测试集集中的数据进行图像增广\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/Users/dylan/anaconda3/Data/keras/re/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/Users/dylan/anaconda3/Data/keras/re/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "#使生成器与模型并行执行，以提高效率\n",
    "model.fit_generator(\n",
    "        train_generator,                      #生成器函数名称\n",
    "        samples_per_epoch=2000,               #数值为整数，当生成器返回2000次数据时计一个epoch结束，执行下一个epoch\n",
    "        nb_epoch=50,                          #数据迭代的轮数\n",
    "        validation_data=validation_generator, #交叉验证集的生成器\n",
    "        nb_val_samples=800)                   #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "intermediate_layer_model = Model(inputs = model.input, \n",
    "                                 outputs = model.get_layer(MaxPooling_1).output)\n",
    "intermediate_output = intermediate_layer_model.predict(data)\n",
    "#data数据应该是原始数据，但是由于在本例中，数据是由生成器产生，所以不能产生data数据直接在这里调用，因此要想办法从生成器中转换成data。。。。\n",
    "#可以先实现mnist数据集的某一层的数据提取。\n",
    "print (intermediate_output.shape)\n",
    "print (intermediate_output[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
